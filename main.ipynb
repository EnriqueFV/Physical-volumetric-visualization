{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is visualization?\n",
        "\n",
        " Informally, visualization is the transformation of data or information into pictures. Visualization engages the primary human sensory apparatus, vision, as well as the processing power of the human mind. The result is a simple and effective medium for communicating complex and/or voluminous information.\n",
        "\n",
        "What the computer represents as a series of numbers, we see as a cross section through the human body: skin, bone, and muscle. Even more impressive results are possible when we extend these techniques into three dimensions. Image slices can be gathered into volumes and the volumes can be processed to reveal complete anatomical structures. Using modern techniques, we can view the entire brain, skeletal system, and vascular system on a living patient without interventional surgery. Such capability has revolutionized modern medical diagnostics, and will increase in importance as imaging and visualization technology matures.\n",
        "\n",
        "Many early uses of visualization were in the engineering and scientific community. From its inception the computer has been used as a tool to simulate physical processes such as ballistic trajectories, fluid flow, and structural mechanics. As the size of the computer simulations grew, it became necessary to transform the resulting calculations into pictures. The amount of data overwhelmed the ability of the human to assimilate and understand it. In fact, pictures were so important that early visualizations were created by manually plotting data. Today, we can take advantage of advances in computer graphics and computer hardware. But, whatever the technology, the application of visualization is the same: to display the results of simulations, experiments, measured data, and fantasy; and to use these pictures to communicate, understand, and entertain.\n",
        "\n",
        "Visualization is a necessary tool to make sense of the flood of information in today’s world of computers. Without visualization, most of this data would sit unseen on computer disks and tapes. Visualization offers some hope that we can extract the important information hidden within the data. There is another important element to visualization: It takes advantage of the natural abilities of the human vision system. Our vision system is a complex and powerful part of our bodies. We use it and rely on it in almost everything we do. Not only do we have strong 2D visual abilities, but also we are adept at integrating different viewpoints and other visual clues into a mental image of a 3D object or plot. Likewise, we have a talent for recognizing temporal changes in an image. Given an animation consisting of hundreds of frames, we have an uncanny ability to recognize trends and spot areas of rapid change.\n",
        "\n",
        "With the introduction of computers and the ability to generate enormous amounts of data, visualization offers the technology to make the best use of our highly developed visual senses. Certainly other technologies such as statistical analysis, artificial intelligence, mathematical filtering, and sampling theory will play a role in large-scale data processing. However, because visualization directly engages the vision system and human brain, it remains an unequaled technology for understanding and communicating data.\n",
        "\n",
        "The output of computer graphics is an image, while the output of visualization is often produced using computer graphics. Sometimes visualization data is in the form of an image, or we wish to visualize object geometry using realistic rendering techniques from computer graphics. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25l98dJfrIAx",
        "outputId": "ccccde1f-07b0-4558-bd07-549798880e38"
      },
      "outputs": [],
      "source": [
        "import pyvista as pv\n",
        "from pyvista import examples\n",
        "import nibabel as nib\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data representation - image data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = r\"copd1_4D.nii.gz\"\n",
        "image_data = nib.load(file_path).get_fdata()\n",
        "# Extraer datos de la fase inspiratoria\n",
        "inspiratory_data = image_data[:, :, :, 0]  # Selecciona la primera fase (índice 0)\n",
        "grid = pv.ImageData()\n",
        "grid.dimensions = np.array(inspiratory_data.shape)\n",
        "grid.origin = (1, 1, 1)\n",
        "grid.spacing = (0.625, 0.625, 2.5)\n",
        "grid.point_data[\"values\"] = inspiratory_data.flatten(order=\"F\")  # Flatten the array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Algoritms\n",
        "methods to transform this data to and from these various representations, eventually generating graphics primitives that we can render. These methods are called algorithms, and are of special interest to those working in the field of visualization. Algorithms are the verbs that allow us to express our data in visual form. By combining these verbs appropriately, we can reduce complex data into simple, readily comprehensible sentences that are the power of data visualization. To describe the various transformations available, we need to categorize algorithms according to the structure and type of transformation. By structure we mean the effects that transformation has on the topology and geometry of the dataset. By type we mean the type of dataset that the algorithm operates on.\n",
        "\n",
        "Structural transformations can be classified in four ways, depending on how they affect the geometry, topology, and attributes of a dataset.\n",
        "\n",
        " - Geometric transformations alter input geometry but do not changed the topology of the dataset. For example, if we translate, rotate, and/or scale the points of a polygonal dataset, the topology does not change, but the point coordinates, and therefore the geometry, does.\n",
        "\n",
        " - Topological transformations alter input topology but do not change geometry and attribute data. Converting a dataset type from polygonal data to unstructured grid data, or from image data to unstructured grid, changes the topology but not the geometry. More often, however, the geometry changes whenever the topology does, so topological transformation is uncommon.\n",
        "\n",
        " - Attribute transformations convert data attributes from one form to another, or create new attributes from the input data. The structure of the dataset remains unaffected. Computing vector magnitude or creating scalars based on elevation are data attribute transformations.\n",
        "\n",
        " - Combined transformations change both dataset structure and attribute data. For example, computing contour lines or surfaces is a combined transformation.\n",
        "\n",
        "We also may classify algorithms according to the type of data they operate on, or the type of data they generate. By type, we most often mean the type of attribute data, such as scalars or vectors. Typical categories include:\n",
        "\n",
        " - Scalar algorithms operate on scalar data. For example, the generation of contour lines of temperature on a weather map.\n",
        "\n",
        " - Vector algorithms operate on vector data. Showing oriented arrows of airflow (direction and magnitude) is an example of vector visualization.\n",
        "\n",
        " - Tensor algorithms operate on tensor matrices. An example of a tensor algorithm is to show the components of stress or strain in a material using oriented icons.\n",
        "\n",
        " - Modelling algorithms generate dataset topology or geometry, or surface normals or texture data. Modelling algorithms tend to be the catch-all category for many algorithms, since some do not fit neatly into any single category mentioned above. For example, generating glyphs oriented according to the vector direction and then scaled according to the scalar value, is a combined scalar/vector algorithm. For convenience we classify such an algorithm as a modelling algorithm, because it does not fit squarely into any other category.\n",
        "\n",
        "\n",
        " Algorithms also can be classified according to the type of data they process. This is the most common scheme found in the visualization literature. However, this scheme is not without its problems. Often the categories overlap, resulting in confusion. For example, a category (not mentioned above) is volume visualization, which refers to the visualization of volume data (or in our terminology, image data). This category was initially created to describe the visualization of scalar data arranged on a volume, but more recently, vector (and even tensor) data has been visualized on a volume. Hence, we have to qualify our techniques to volume vector visualization, or other potentially confusing combinations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scalar algorithms\n",
        "\n",
        "Most algorithms can be written specifically for a particular dataset type, or more generally, treating any dataset type. The advantage of a specific algorithm is that it is usually faster than a comparable general algorithm. An implementation of a specific algorithm also may be more memory efficient and its implementation may better reflect the relationship between the algorithm and the dataset type it operates on. One example of this is contour surface creation. Algorithms for extracting contour surfaces were originally developed for volume data, mainly for medical applications. The regularity of volumes lends itself to efficient algorithms. However, the specialization of volume-based algorithms precludes their use for more general datasets such as structured or unstructured grids. Although the contour algorithms can be adapted to these other dataset types, they are less efficient than those for volume datasets. Our presentation of algorithms favors the more general implementations.\n",
        "\n",
        "Fundamental algorithms (surface model): \n",
        " - Color map: is a common scalar visualization technique that maps scalar data to colors, and displays the colors on the computer system. The scalar mapping is implemented by indexing into a color lookup table. Scalar values serve as indices into the lookup table.\n",
        "\n",
        "  - Transfer fuction: A more general form of the lookup table is called a transfer function. A transfer function maps any expression that maps scalar value into a color specification. For example, scalar values into separate intensity values for the red, green, and blue color components. We can also use transfer functions to map scalar data into other information such as local transparency. A lookup table is a discrete sampling of a transfer function. We can create a lookup table from any transfer function by sampling the transfer function at a set of discrete points.\n",
        "  \n",
        "  - Contourning: A natural extension to color mapping is contouring. When we see a surface colored with data values, the eye often separates similarly colored areas into distinct regions. When we contour data, we are effectively constructing the boundary between these regions. These boundaries correspond to contour lines (2D) or surfaces (3D) of constant scalar value.Three-dimensional contours are called isosurfaces, and can be approximated by many polygonal primitives.  Examples of isosurfaces include constant medical image intensity corresponding to body tissues such as skin, bone, or other organs. \n",
        "    - Since the most common interpolation technique is linear, we generate points on the contour surface by linear interpolation along the edges. If an edge has scalar values 10 and 0 at its two endpoints, and if we are trying to generate a contour line of value 5, then edge interpolation computes that the contour passes through the midpoint of the edge.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Object oriented "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Surface model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "Q0yHCbHorIAy",
        "outputId": "f32964a9-81a3-4b2b-c998-6482a8873534"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "790eccc627a84ef995231f2097a2f1e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Widget(value='<iframe src=\"http://localhost:62496/index.html?ui=P_0x19761fa23f0_0&reconnect=auto\" class=\"pyvis…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pl = pv.Plotter(shape=[1,3])\n",
        "_ = pl.add_mesh(grid)\n",
        "pl.add_text(\"Color map\")\n",
        "pl.subplot(0, 1)\n",
        "_ = pl.add_mesh_isovalue(grid)\n",
        "pl.add_text(\"isovalue\")\n",
        "pl.subplot(0, 2)\n",
        "\n",
        "isovalues = grid.contour(np.linspace(0, 2000, 5), method='contour') #'contour', 'marching_cubes' and 'flying_edges'\n",
        "# Create a new lookup table with oranges\n",
        "lut = pv.LookupTable()\n",
        "lut.value_range = (0, 2000)\n",
        "lut.hue_range = (0.0, 1)\n",
        "lut.saturation_range = (0.0, 1)\n",
        "lut.alpha_range = (0.0, 1.0)\n",
        "lut.scalar_range = (1, 2000)\n",
        "\n",
        "scalars_rng = (isovalues.active_scalars.min(), isovalues.active_scalars.max())\n",
        "\n",
        "\n",
        "def make_double_slider(attr, idx):\n",
        "    \"\"\"Create a double slider for a given lookup table attribute.\"\"\"\n",
        "\n",
        "    def set_min(min_value):\n",
        "        max_value = getattr(lut, attr)[1]\n",
        "        if min_value > max_value:\n",
        "            # force the movement of the maximum value\n",
        "            max_value = min_value\n",
        "            pl.slider_widgets[idx * 2 + 1].GetRepresentation().SetValue(max_value)\n",
        "        setattr(lut, attr, (min_value, max_value))\n",
        "\n",
        "        if attr == 'scalar_range':\n",
        "            actor.mapper.scalar_range = getattr(lut, attr)\n",
        "\n",
        "    def set_max(max_value):\n",
        "        min_value = getattr(lut, attr)[0]\n",
        "        if max_value < min_value:\n",
        "            # force the movement of the minimum value\n",
        "            min_value = max_value\n",
        "            pl.slider_widgets[idx * 2].GetRepresentation().SetValue(min_value)\n",
        "        setattr(lut, attr, (min_value, max_value))\n",
        "\n",
        "        if attr == 'scalar_range':\n",
        "            actor.mapper.scalar_range = getattr(lut, attr)\n",
        "\n",
        "    if attr == 'scalar_range':\n",
        "        rng = scalars_rng\n",
        "    else:\n",
        "        rng = (0, 1)\n",
        "\n",
        "    # create two overlapping slider bars by hiding the tube of the second\n",
        "    pl.add_slider_widget(\n",
        "        set_min,\n",
        "        rng,\n",
        "        value=getattr(lut, attr)[0],\n",
        "        interaction_event='always',\n",
        "        title=' '.join(attr.split('_')).capitalize(),\n",
        "        tube_width=0.003,\n",
        "        pointa=(0.6, 0.9 - 0.165 * idx),\n",
        "        pointb=(0.9, 0.9 - 0.165 * idx),\n",
        "    )\n",
        "    pl.add_slider_widget(\n",
        "        set_max,\n",
        "        rng,\n",
        "        value=getattr(lut, attr)[1],\n",
        "        interaction_event='always',\n",
        "        tube_width=0.0,\n",
        "        pointa=(0.6, 0.9 - 0.165 * idx),\n",
        "        pointb=(0.9, 0.9 - 0.165 * idx),\n",
        "    )\n",
        "actor = pl.add_mesh(isovalues, cmap=lut, lighting=False)\n",
        "make_double_slider('alpha_range', 0)\n",
        "make_double_slider('hue_range', 1)\n",
        "make_double_slider('value_range', 2)\n",
        "make_double_slider('saturation_range', 3)\n",
        "make_double_slider('scalar_range', 4)\n",
        "pl.add_text(\"5 isovalues\")\n",
        "\n",
        "pl.link_views()\n",
        "pl.camera_position = [(-grid.center[0], -grid.center[1]*10, grid.center[2]), grid.center, (0,0, -1)]\n",
        "pl.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Volume model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74f6b7380cf3439aafe7c7696ae37a01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Widget(value='<iframe src=\"http://localhost:62496/index.html?ui=P_0x1975f3e3230_1&reconnect=auto\" class=\"pyvis…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pl = pv.Plotter(shape=(2, 2))\n",
        "\n",
        "pl.add_volume(grid, scalar_bar_args={'title': \"No Opacity\"})\n",
        "\n",
        "pl.subplot(0, 1)\n",
        "pl.add_volume(grid, opacity=\"linear\", scalar_bar_args={'title': \"Linear Opacity\"})\n",
        "\n",
        "pl.subplot(1, 0)\n",
        "pl.add_volume(grid, opacity=\"sigmoid\", scalar_bar_args={'title': \"Sigmoidal Opacity\"})\n",
        "\n",
        "pl.subplot(1, 1)\n",
        "pl.add_volume(grid, opacity=\"geom_r\", scalar_bar_args={'title': \"Log Scale Opacity\"})\n",
        "pl.camera_position = [(-grid.center[0], -grid.center[1]*10, grid.center[2]), grid.center, (0,0, -1)]\n",
        "pl.link_views()\n",
        "pl.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "201c8fe02b854554b4c84751ae92d959",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Widget(value='<iframe src=\"http://localhost:51913/index.html?ui=P_0x1dc81227750_2&reconnect=auto\" class=\"pyvis…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pl = pv.Plotter()\n",
        "pl.add_mesh_threshold(grid)\n",
        "pl.camera_position = [(-grid.center[0], -grid.center[1]*10, grid.center[2]), grid.center, (0,0, -1)]\n",
        "pl.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#\n",
        "The two visualization algorithms presented thus far, color mapping and contouring, along with opacity alpha values/ transfer function, are simple, effective methods to display scalar information. It is natural to turn to these algorithms first when visualizing data. However, often our data is not in a form convenient to these techniques. The data may not be single-valued (i.e., a scalar), or it may be a mathematical or other complex relationship. That is part of the fun and creative challenge of visualization: We must tap our creative resources to convert data into a form we can visualize. \n",
        "\n",
        "Other examples of scalar mapping include an index value into a list of data, computing vector magnitude or matrix determinate, evaluating surface curvature, or determining distance between points. Scalar generation, when coupled with color mapping or contouring, is a simple, yet effective, technique for visualizing many types of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image oriented rendering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "cb93602252c64a5489c78f8c82860099"
          ]
        },
        "id": "QFZhMqb2rIAz",
        "outputId": "730dbcd7-f89e-4cfc-93b3-ba6962974241"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "615566eb976c424d8b458d6457ef5295",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Widget(value='<iframe src=\"http://localhost:51913/index.html?ui=P_0x1dccc66af90_4&reconnect=auto\" class=\"pyvis…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Download skybox\n",
        "# cubemap = examples.download_sky_box_cube_map()\n",
        "cubemap = examples.download_cubemap_space_4k()\n",
        "grid = grid.contour(isosurfaces= [600], progress_bar= True, method='marching_cubes') #'contour', 'marching_cubes' and 'flying_edges'\n",
        "pl = pv.Plotter()\n",
        "pl.add_actor(cubemap.to_skybox())\n",
        "pl.set_environment_texture(cubemap)  # For reflecting the environment off the mesh\n",
        "pl.add_mesh(grid, color='ff9999', opacity = 0.5, ambient= 1,diffuse=1,specular= 1, lighting= True, roughness=1.0, metallic=0.0,pbr=True, interpolate_before_map=False, use_transparency=True, render = True)\n",
        "pl.add_text(\"generic illumination scene\")\n",
        "pl.camera_position = [(-grid.center[0], -grid.center[1]*10, grid.center[2]), grid.center, (0,0, -1)]\n",
        "pl.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing Contour:   0%|          [00:00<?]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing Contour: 100%|██████████[00:01<00:00]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97f8e19810cb46d1b331a694eed21bf2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Widget(value='<iframe src=\"http://localhost:61995/index.html?ui=P_0x17055d3cad0_2&reconnect=auto\" class=\"pyvis…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "grid = grid.contour(isosurfaces= [600], progress_bar= True, method='marching_cubes') #'contour', 'marching_cubes' and 'flying_edges'\n",
        "plotter = pv.Plotter(lighting='none')\n",
        "plotter.set_background('black')\n",
        "plotter.add_mesh(grid, color= 'ff9999', opacity = 0.5, ambient= 1,diffuse=1,specular= 1, lighting= True, roughness=0.1, metallic=0.1,pbr=True, interpolate_before_map=True, use_transparency=True)\n",
        "# floor = pv.Plane(center=(*grid.center[:2], grid.bounds[-1]), i_size=1000, j_size=1000)\n",
        "# plotter.add_mesh(floor, color='green')\n",
        "\n",
        "UFO = pv.Light(position=(grid.center[0],grid.center[1],grid.bounds[-2]*(-200)), focal_point=grid.center, color='white')\n",
        "UFO.positional = True\n",
        "UFO.cone_angle = 45\n",
        "UFO.exponent = 10\n",
        "UFO.intensity = 1\n",
        "UFO.show_actor()\n",
        "plotter.add_light(UFO)\n",
        "\n",
        "UFO2 = pv.Light(position=(grid.center[0],grid.bounds[3] * 2,grid.center[2]), focal_point=grid.center, color='white')\n",
        "UFO2.positional = True\n",
        "UFO2.cone_angle = 45\n",
        "UFO2.exponent = 10\n",
        "UFO2.intensity = 1\n",
        "UFO2.show_actor()\n",
        "plotter.add_light(UFO2)\n",
        "\n",
        "UFO3 = pv.Light(position=(grid.center[0], - grid.bounds[3] * 2,grid.center[2]), focal_point=grid.center, color='white')\n",
        "UFO3.positional = True\n",
        "UFO3.cone_angle = 45\n",
        "UFO3.exponent = 10\n",
        "UFO3.intensity = 1\n",
        "UFO3.show_actor()\n",
        "plotter.add_light(UFO3)\n",
        "\n",
        "UFO4 = pv.Light(position=(grid.bounds[1]*2,grid.center[1],grid.center[2]), focal_point=grid.center, color='white')\n",
        "UFO4.positional = True\n",
        "UFO4.cone_angle = 45\n",
        "UFO4.exponent = 10\n",
        "UFO4.intensity = 1\n",
        "UFO4.show_actor()\n",
        "plotter.add_light(UFO4)\n",
        "\n",
        "UFO5 = pv.Light(position=(-grid.bounds[1]*2,grid.center[1],grid.center[2]), focal_point=grid.center, color='white')\n",
        "UFO5.positional = True\n",
        "UFO5.cone_angle = 45\n",
        "UFO5.exponent = 10\n",
        "UFO5.intensity = 1\n",
        "UFO5.show_actor()\n",
        "plotter.add_light(UFO5)\n",
        "\n",
        "# enable shadows to better demonstrate lighting\n",
        "plotter.enable_shadows()\n",
        "plotter.camera_position = [(-grid.center[0], -grid.center[1]*10, grid.center[2]), grid.center, (0,0, -1)]\n",
        "plotter.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
